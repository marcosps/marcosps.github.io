[{"content":"It\u0026rsquo;s known that btrfs behaves differently from other Linux filesystems. There are some fascinating aspects of how btrfs manages its internal structures and how common tools are not prepared to handle it.\nThis goal of this post is to demystify why ext4 can report the number of available inodes while btrfs always reports 0:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  $ file ext4.disk ext4.disk: Linux rev 1.0 ext4 filesystem data, UUID=3f21312b-412a-4b1a-8561-5704eaf39d22 (extents) (64bit) (large files) (huge files) $ mount ext4.disk /mnt $ df -i /mnt Filesystem Inodes IUsed IFree IUse% Mounted on /dev/loop0 327680 11 327669 1% /mnt $ mount -l | grep sda2 /dev/sda2 on / type btrfs (rw,relatime,ssd,space_cache=v2,subvolid=266,subvol=/@/.snapshots/1/snapshot) $ df -i / Filesystem Inodes IUsed IFree IUse% Mounted on /dev/sda2 0 0 0 - /   Why btrfs always shows the number of available inodes as zero? This aspect tells a lot about how btrfs manages its physical space.\nFilesystems like ext4 allocate the entire disk on filesystem creation time, creating block groups all over the available space. This means that once the spaces for data and metadata are defined, they cannot be changed after the filesystem is in use, as there isn\u0026rsquo;t a way to extend them: they have fixed offsets. Let\u0026rsquo;s take a look how it works for ext4.\nExt4: block sizes and block groups In filesystems, a block is a group of sectors (512 bytes) and it\u0026rsquo;s the smaller unit of data managed by the filesystem. The block size affects all other filesystem structures, specially in filesystems like ext4 for example. By the block size we can say how many inodes and how much space a ext4 filesystem can manage. Ext4 accepts block sizes of 1k, 2k, 4k and 64k.\nA block group, as the name implies, is a collection of blocks, and many filesystems manage their spaces using block groups. Ext4 divides the entire disk into block groups when creating the filesystem and its size is defined by the block size. By default, ext4 uses blocks of 4k of size. Ext4 stores both data and metadata in a block group.\nFrom now on we\u0026rsquo;ll make the calculations based in a block size of 4k (4096 bytes).\nTo track which blocks are used in a block group, ext4 reserves one block of the block group to store a bitmap. Each bit of the bitmap will track one block of the block group, meaning that we can map up to 128mb of space:\n4096 bytes * 8bits: 32768 bits 32768 bits can map 32768 blocks of 4k 32768 * 4k: 134217728 bytes: 128Mb Let\u0026rsquo;s take a look in how ext4 divides a 5G disk, using the default 4k block sizes:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  # create a 5G file to be used as disk $ fallocate -l5g ext4.disk # create the ext4 filesystem on it $ mkfs.ext4 ext4.disk mke2fs 1.43.8 (1-Jan-2018) Discarding device blocks: done Creating filesystem with 1310720 4k blocks and 327680 inodes Filesystem UUID: e408e28f-f275-49c6-87e8-18104fe31ba4 Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736 Allocating group tables: done Writing inode tables: done Creating journal (16384 blocks): done Writing superblocks and filesystem accounting information: done # print some information about the created filesystem $ dumpe2fs ext4.disk dumpe2fs 1.43.8 (1-Jan-2018) Filesystem volume name: \u0026lt;none\u0026gt; Last mounted on: \u0026lt;not available\u0026gt; Filesystem UUID: e408e28f-f275-49c6-87e8-18104fe31ba4 Filesystem magic number: 0xEF53 Filesystem revision #: 1 (dynamic) Filesystem features: has_journal ext_attr resize_inode dir_index filetype extent 64bit flex_bg sparse_super large_file huge_file uninit_bg dir_nlink extra_isize Filesystem flags: signed_directory_hash Default mount options: user_xattr acl Filesystem state: clean Errors behavior: Continue Filesystem OS type: Linux Inode count: 327680 Block count: 1310720 Reserved block count: 65536 Free blocks: 1268642 Free inodes: 327669 First block: 0 Block size: 4096 Fragment size: 4096 Group descriptor size: 64 Reserved GDT blocks: 639 Blocks per group: 32768 Fragments per group: 32768 Inodes per group: 8192 Inode blocks per group: 512 Flex block group size: 16 Filesystem created: Wed Aug 4 00:24:49 2021 ... First inode: 11 Inode size: 256 ... Group 0: (Blocks 0-32767) csum 0xcef6 [ITABLE_ZEROED] Primary superblock at 0, Group descriptors at 1-1 Reserved GDT blocks at 2-640 Block bitmap at 641 (+641) Inode bitmap at 657 (+657) Inode table at 673-1184 (+673) 23897 free blocks, 8181 free inodes, 2 directories, 8181 unused inodes Free blocks: 8871-32767 Free inodes: 12-8192 Group 1: (Blocks 32768-65535) csum 0x4873 [INODE_UNINIT, BLOCK_UNINIT, ITABLE_ZEROED] Backup superblock at 32768, Group descriptors at 32769-32769 Reserved GDT blocks at 32770-33408 Block bitmap at 642 (bg #0 + 642) Inode bitmap at 658 (bg #0 + 658) Inode table at 1185-1696 (bg #0 + 1185) 32127 free blocks, 8192 free inodes, 0 directories, 8192 unused inodes Free blocks: 33409-65535 Free inodes: 8193-16384 ... Group 39: (Blocks 1277952-1310719) csum 0x71eb [INODE_UNINIT, ITABLE_ZEROED] Block bitmap at 1048583 (bg #32 + 7) Inode bitmap at 1048591 (bg #32 + 15) Inode table at 1052176-1052687 (bg #32 + 3600) 32768 free blocks, 8192 free inodes, 0 directories, 8192 unused inodes Free blocks: 1277952-1310719 Free inodes: 319489-327680   The output of mkfs.ext4 was reduced because it\u0026rsquo;s too long. The output above gives a general idea about how the filesystem is organized. From now on this post will describe how these values are calculated, and why they were chosen by ext4.\nAs ext4 manages its spaces using block groups, and with 4k block sizes we can have a block group mapping up to 128Mb of space, mkfs.ext4 needed to create 40 block groups:\n5G of space / 128mb block group size: 40 block groups Ext4: inodes As mentioned before ext4 uses a reserved block in a block group to track the used blocks. This is also true for inodes. There is a reserved block per block group used as an inode bitmap to track allocated inodes. By using the same math, the inode bitmap can track up to 32768 inodes.\nAlong with the inode bitmap, we also need to store the inode metadata (size, owner, file size, etc). There is a space in the block group to store the inode metadata, and it\u0026rsquo;s separated from the file\u0026rsquo;s data.\nAs each block group is allocated when creating the filesystem, and inode metadata has to have a separated space within the block group (called inode table) it needs to calculate the necessary space to store the metadata.\nIf a big amount of space is used to store inode metadata, the filesystem would be able to create more files, but the available space for file content (data) would be reduced. On the other hand, creating a small inode table allows the user to store more data, but with a reduced number of files. To address these limits, mkfs.ext4 uses a configuration called inode-ratio which defines the number of inodes proportional to the storage space. The default inode-ratio is 16k (described in mke2fs.conf file).\nUsing our 5G disk as before and the inode-ration, we can calculate the maximum number of inodes this filesystem can store:\n5G of storage / 16k: 327680 inodes 327680 inodes / 40 block groups: 8192 These values match the output from mkfs.ext4 shown before.\nThe inode table needs to known how much space will be used to store the inode metadata for each inode in the filesystem. Ext4 uses 256 bytes as default inode size (also described in mke2fs.conf file), so for each block group it will use 2Mb of space for the inode table:\n8192 inodes x 256 bytes per inode: 2Mb (2097152 bytes) To compare the numbers, just mount the filesystem created before and use df to show the maximum number of inodes:\n1 2 3 4 5 6 7  $ mount ext4.disk /tmp/ext4 $ df -i /tmp/ext4 Filesystem Inodes IUsed IFree IUse% Mounted on /dev/loop0 327680 11 327669 1% /tmp/ext4 $ ls -i /tmp/ext4 11 lost+found   Ext4 reserves the inode numbers from 0 to 10 for special purposes, and the first usable one is for the lost+found. This is a special purpose directory for the ext4 filesystem. All user files start from inode 12.\nFor more information about ext4 block group please check the official ext4 documentation here.\nWhat about btrfs? Btrfs allocates its structures dynamically. From block groups to internal structures and inodes, btrfs allocates them on demand.\nBtrfs: block groups Btrfs also uses block groups to manage the filesystem space, but each block group will store data OR metadata, not both. On filesystem creation time we can specify the block groups to be mixed, containing both data and metadata, but it\u0026rsquo;s not recommended.\nWhen creating a filesystem btrfs creates a block group to store data, one to store metadata, and one system block group. A data block group (usually) takes 1G of size, while the metadata one can take 256Mb if the filesystem is smaller than 50G, and 1G if bigger. The system block group usually takes up to some megabytes. For small filesystems, the block group sizes cannot be more than 10% of the filesystem size, so it can smaller than 1G as stated before. All the remaining space is left there to be allocated when necessary.\nDifferently from ext4, btrfs allocates block groups on demand. If the workload is focused on data (bigger files), more data block groups will be allocated from the free space. In the same way, if the workload is creating more metadata (doing snapshots for example) more metadata block groups will be allocated.\nLet\u0026rsquo;s see an example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  # create a 55G file to be used as disk $ fallocate -l55g btrfs.disk # Create the filesystem on top of it $ mkfs.btrfs -f /storage/btrfs.disk btrfs-progs v5.10.1 See http://btrfs.wiki.kernel.org for more information. Label: (null) UUID: 8f9303a9-15cd-4709-848e-38f80b5b2985 Node size: 16384 Sector size: 4096 Filesystem size: 55.00GiB Block group profiles: Data: single 1.00GiB Metadata: DUP 1.00GiB System: DUP 8.00MiB SSD detected: no Zoned device: no Incompat features: extref, skinny-metadata Runtime features: Checksum: crc32c Number of devices: 1 Devices: ID SIZE PATH 1 55.00GiB /storage/btrfs.disk   If your filesystem reports a different data block group as being of 8M, it\u0026rsquo;s because of this issue that was reported, but maybe not yet fixed. It\u0026rsquo;s important to understand that these numbers reflect the allocation strategy for single profile. For raid setups, these numbers can be different.\nAlso, the block group sizes doesn\u0026rsquo;t affect the number of maximum number of inodes that can be created, as we\u0026rsquo;ll see later.\nWe can inspect the block groups by using the btrfs tool:\n1 2 3 4 5 6 7 8  $ btrfs inspect-internal dump-tree -t extent /storage/btrfs.disk | grep -A1 BLOCK_GROUP item 0 key (1078984704 BLOCK_GROUP_ITEM 1073741824) itemoff 16259 itemsize 24 block group used 0 chunk_objectid 256 flags DATA item 1 key (2152726528 BLOCK_GROUP_ITEM 8388608) itemoff 16235 itemsize 24 block group used 16384 chunk_objectid 256 flags SYSTEM|DUP ... item 4 key (2161115136 BLOCK_GROUP_ITEM 1073741824) itemoff 16145 itemsize 24 block group used 114688 chunk_objectid 256 flags METADATA|DUP   The above command used the inspect-internal subcommand to dump the entire extent-tree. We can compare the block group sizes (the numbers after the BLOCK_GROUP_ITEM) in bytes that match we the previous mkfs.btrfs output. The profiles are also dumped and can be verified, being DUP for system and metadata.\nWhen we write more files, or if a file occupies more than 1G of data, more data block groups are created (the flags field shows the type of the block group):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # Creating a 2.5G file $ dd if=/dev/urandom of=/mnt/testing/file.bin bs=1M count=2500 $ sync # Check the new data block groups $ btrfs inspect-internal dump-tree -t extent /storage/btrfs.disk| grep -A1 BLOCK_GROUP item 0 key (1078984704 BLOCK_GROUP_ITEM 1073741824) itemoff 16259 itemsize 24 block group used 940572672 chunk_objectid 256 flags DATA .. item 13 key (2152726528 BLOCK_GROUP_ITEM 8388608) itemoff 15619 itemsize 24 block group used 16384 chunk_objectid 256 flags SYSTEM|DUP item 14 key (2161115136 BLOCK_GROUP_ITEM 1073741824) itemoff 15595 itemsize 24 block group used 2899968 chunk_objectid 256 flags METADATA|DUP .. item 192 key (3234856960 BLOCK_GROUP_ITEM 1073741824) itemoff 9730 itemsize 24 block group used 939524096 chunk_objectid 256 flags DATA .. item 201 key (4308598784 BLOCK_GROUP_ITEM 1073741824) itemoff 9282 itemsize 24 block group used 742391808 chunk_objectid 256 flags DATA   We can see that new data block groups were created. If we remove the file, the used space is updated to reflect the file removal:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  $ rm /mnt/testing/file.bin $ sync $ btrfs inspect-internal dump-tree -t extent /storage/btrfs.disk| grep -A1 BLOCK_GROUP item 1 key (1078984704 BLOCK_GROUP_ITEM 1073741824) itemoff 16206 itemsize 24 block group used 1048576 chunk_objectid 256 flags DATA .. item 6 key (2152726528 BLOCK_GROUP_ITEM 8388608) itemoff 15990 itemsize 24 block group used 16384 chunk_objectid 256 flags SYSTEM|DUP item 7 key (2161115136 BLOCK_GROUP_ITEM 1073741824) itemoff 15966 itemsize 24 block group used 147456 chunk_objectid 256 flags METADATA|DUP .. item 17 key (3234856960 BLOCK_GROUP_ITEM 1073741824) itemoff 15645 itemsize 24 block group used 0 chunk_objectid 256 flags DATA item 18 key (4308598784 BLOCK_GROUP_ITEM 1073741824) itemoff 15621 itemsize 24 block group used 0 chunk_objectid 256 flags DATA   Take a look in the block group use field, they are now zeroed. The block groups are still allocated, but a balance can remove the non used ones:\n1 2 3 4 5 6 7 8 9 10 11  $ btrfs balance start -dusage=0 /mnt/testing Done, had to relocate 0 out of 3 chunks $ btrfs inspect-internal dump-tree -textent /storage/btrfs.disk | grep -A 1 BLOCK_GROUP item 0 key (1078984704 BLOCK_GROUP_ITEM 1073741824) itemoff 16259 itemsize 24 block group used 524288 chunk_objectid 256 flags DATA .. item 3 key (2152726528 BLOCK_GROUP_ITEM 8388608) itemoff 16129 itemsize 24 block group used 16384 chunk_objectid 256 flags SYSTEM|DUP .. item 5 key (2161115136 BLOCK_GROUP_ITEM 1073741824) itemoff 16072 itemsize 24 block group used 147456 chunk_objectid 256 flags METADATA|DUP   It shows only one data block group.\nBtrfs: inodes Btrfs does not use fixes inode bitmaps for inode allocation. As stated before, btrfs allocates internal items to manage its metadata. Each item is addressed by three values that together compose a key. These values are described as objectid, type and offset.\nThis is the fs tree right after the filesystem is created:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  $ btrfs inspect-internal dump-tree -t fs /storage/btrfs.disk btrfs-progs v5.16.1 fs tree key (FS_TREE ROOT_ITEM 0) leaf 30474240 items 2 free space 16061 generation 5 owner FS_TREE leaf 30474240 flags 0x1(WRITTEN) backref revision 1 fs uuid b62385e4-e0cc-497f-a220-29ae6465510d chunk uuid b3e0fa4d-fddb-40b3-bd9c-349df8095b39 item 0 key (256 INODE_ITEM 0) itemoff 16123 itemsize 160 generation 3 transid 0 size 0 nbytes 16384 block group 0 mode 40755 links 1 uid 0 gid 0 rdev 0 sequence 0 flags 0x0(none) atime 1650811378.0 (2022-04-24 11:42:58) ctime 1650811378.0 (2022-04-24 11:42:58) mtime 1650811378.0 (2022-04-24 11:42:58) otime 1650811378.0 (2022-04-24 11:42:58) item 1 key (256 INODE_REF 256) itemoff 16111 itemsize 12 index 0 namelen 2 name: ..   There are two items in the listing, and the two refer to the top level directory. The INODE_ITEM item contains data about the inode, owner, size and etc. Its key is always (inode_number INODE_ITEM 0), and 256 is the first inode number used in a filesystem tree.\nThe INODE_REF item maps an inode to its parent directory (inode_number INODE_REF parent_dir_inode). In this case it points to itself since the top level directory ancestor is itself.\nBy creating a file, we can see more structures being allocated:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  $ touch /mnt/testing/file.txt $ sync $ btrfs inspect-internal dump-tree -t fs /storage/btrfs.disk ... item 2 key (256 DIR_ITEM 3956591618) itemoff 16073 itemsize 38 location key (257 INODE_ITEM 0) type FILE transid 9 data_len 0 name_len 8 name: file.txt item 3 key (256 DIR_INDEX 2) itemoff 16035 itemsize 38 location key (257 INODE_ITEM 0) type FILE transid 9 data_len 0 name_len 8 name: file.txt item 4 key (257 INODE_ITEM 0) itemoff 15875 itemsize 160 generation 9 transid 9 size 0 nbytes 0 block group 0 mode 100644 links 1 uid 0 gid 0 rdev 0 sequence 10 flags 0x0(none) atime 1650811865.463886516 (2022-04-24 11:51:05) ctime 1650811865.463886516 (2022-04-24 11:51:05) mtime 1650811865.463886516 (2022-04-24 11:51:05) otime 1650811865.463886516 (2022-04-24 11:51:05) item 5 key (257 INODE_REF 256) itemoff 15857 itemsize 18 index 2 namelen 8 name: file.txt   A new INODE_ITEM was allocated for file.txt, using the inode number 257. The new INODE_REF item\u0026rsquo;s offset points to 256, which is the top level directory, as expected.\nTwo new items are also allocated: DIR_ITEM and DIR_INDEX. DIR_INDEX is used for directory listing, like readdir for example. Its key (parent_dir_inode DIR_INDEX pos) almost explains itself. The pos value says it\u0026rsquo;s the third file created in the directory, as values 1 and 2 are related to \u0026lsquo;.\u0026rsquo; and \u0026lsquo;..\u0026rsquo; respectively. DIR_ITEM is used for searching. Its offset value is the filename hashed, making it quick to find a file by name inside a directory.\nAs the file grows, more item are created:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  $ dd if=/dev/urandom of=/mnt/testing/file.txt bs=1M count=500 $ sync $ btrfs inspect-internal dump-tree -t fs btrfs.disk ... item 6 key (257 EXTENT_DATA 0) itemoff 15804 itemsize 53 generation 12 type 1 (regular) extent data disk byte 1104150528 nr 134217728 extent data offset 0 nr 134217728 ram 134217728 extent compression 0 (none) item 7 key (257 EXTENT_DATA 134217728) itemoff 15751 itemsize 53 generation 12 type 1 (regular) extent data disk byte 1238368256 nr 134217728 extent data offset 0 nr 134217728 ram 134217728 extent compression 0 (none) item 8 key (257 EXTENT_DATA 268435456) itemoff 15698 itemsize 53 generation 12 type 1 (regular) extent data disk byte 1372585984 nr 134217728 extent data offset 0 nr 134217728 ram 134217728 extent compression 0 (none) item 9 key (257 EXTENT_DATA 402653184) itemoff 15645 itemsize 53 generation 12 type 1 (regular) extent data disk byte 1506803712 nr 90177536 extent data offset 0 nr 90177536 ram 90177536 extent compression 0 (none) item 10 key (257 EXTENT_DATA 492830720) itemoff 15592 itemsize 53 generation 12 type 1 (regular) extent data disk byte 1596981248 nr 1048576 extent data offset 0 nr 1048576 ram 1048576 extent compression 0 (none) item 11 key (257 EXTENT_DATA 493879296) itemoff 15539 itemsize 53 generation 12 type 1 (regular) extent data disk byte 1598029824 nr 30408704 extent data offset 0 nr 30408704 ram 30408704 extent compression 0 (none) ...   New EXTENT_DATA items are created to manage the data related to user files. The objectid of the EXTENT_DATA\u0026rsquo;s key informs to which inode the data is associated.\nMore data about btrfs item can be found in this document.\nWhy can\u0026rsquo;t btrfs show how many inodes it can hold? Because it\u0026rsquo;s impossible to known beforehand.\nThe same metadata block group space is used to store INODE_ITEM, EXTENT_DATA and all other metadata items. So if a workload creates bigger files, it ends ups creating more EXTENT_DATA items, which can end up consuming a huge number of metadata block groups to manage extents.\nOn the other hand, if your workload ends up creating a huge number of small files, it would end up creating less EXTENT_DATA items, making it possible to store different items, including INODE_ITEMs, making it possible to create more files.\nThat\u0026rsquo;s the reason for the number of inodes cannot be checked by using df. The df tool uses the statfs system call to show the information about inodes. The system call populates the statfs struct with the values related to the filesystem being checked, and the f_files field contains the maximum number of inodes.\nBy looking at the kernel code, the function btrfs_statfs does not set buf-\u0026gt;f_files, while in ext4_statfs we can see the information being get from the superblock.\nBtrfs: Inodes and subvolumes In btrfs, subvolumes store user data, and act like different filesystems, as each subvolume can be mounted separately. It can be compared to a disk partition, but having much more features, like creating snapshots. openSUSE and SUSE Linux Enterprise (SLE) uses subvolumes to divide the filesystem into logic structures, and also to manage snapshots after each upgrade:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  $ btrfs subvolume list / [sudo] password for root: ID 256 gen 31 top level 5 path @ ID 257 gen 161195 top level 256 path @/var ID 258 gen 161097 top level 256 path @/usr/local ID 259 gen 64676 top level 256 path @/srv ID 260 gen 149398 top level 256 path @/root ID 261 gen 146119 top level 256 path @/opt ID 262 gen 161195 top level 256 path @/home ID 263 gen 150062 top level 256 path @/boot/grub2/x86_64-efi ID 264 gen 27 top level 256 path @/boot/grub2/i386-pc ID 265 gen 160386 top level 256 path @/.snapshots ID 266 gen 161162 top level 265 path @/.snapshots/1/snapshot ID 342 gen 110017 top level 265 path @/.snapshots/77/snapshot ID 343 gen 110254 top level 265 path @/.snapshots/78/snapshot ID 346 gen 112147 top level 265 path @/.snapshots/81/snapshot ID 347 gen 112149 top level 265 path @/.snapshots/82/snapshot ID 352 gen 113071 top level 265 path @/.snapshots/87/snapshot ID 353 gen 113100 top level 257 path @/var/lib/machines ...   An interesting fact about subvolumes is that files always start from inode 257, and the same inode numbers are used in different subvolumes. Since each subvolume is a different tree inside btrfs, it\u0026rsquo;s not a problem for the end user. Let\u0026rsquo;s see an example of this happening:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  $ mount /storage/btrfs.disk /mnt/testing $ btrfs subvolume create /mnt/testing/vol1 Create subvolume \u0026#39;/mnt/testing/vol1\u0026#39; $ btrfs subvolume create /mnt/testing/vol2 Create subvolume \u0026#39;/mnt/testing/vol2\u0026#39; # let\u0026#39;s create directories and files inside each subvolume $ touch /mnt/testing/vol1/file1 $ touch /mnt/testing/vol1/file2 $ mkdir /mnt/testing/vol2/dir1 $ touch /mnt/testing/vol2/filexx # let\u0026#39;s list the inodes of there files/direcotry $ ls -iR /mnt/testing /mnt/testing: 256 vol1 256 vol2 /mnt/testing/vol1: 257 file1 258 file2 /mnt/testing/vol2: 257 dir1 258 filexx /mnt/testing/vol2/dir1:   From the output above we can see that both file1 and dir, and file2 and filexx have the same inode numbers.\nConsiderations Interested readers may want to take a look into the ext4 kernel documentation , the mke2fs documentation and the configuration file used by mke2fs for the default filesystem settings.\nBtrfs has a nice wiki page detailing how things work. Additional info can be get from the mkfs.btrfs utility man page and for the more curious readers, the btrfs-dev-docs details the inner parts of the filesystem.\nThe post got much bigger than I expected. The initial focus was to only mention about the kernel code setting the number of inodes in ex4, and the math involved to find the maximum number of inodes. While talking with some friends, it became more evident that more background would be more interesting. So that explains why block groups, subvolumes and everything in between was mentioned.\nThanks for reading!\n","permalink":"https://mpdesouza.com/blog/btrfs-for-mere-mortals-inode-allocation/","summary":"It\u0026rsquo;s known that btrfs behaves differently from other Linux filesystems. There are some fascinating aspects of how btrfs manages its internal structures and how common tools are not prepared to handle it.\nThis goal of this post is to demystify why ext4 can report the number of available inodes while btrfs always reports 0:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  $ file ext4.","title":"Btrfs for mere mortals: inode allocation"},{"content":"Tools like fsck and smartctl are usually used when something bad happens on your disk. But, what if such tools have a problem and also need to be fixed? Well, that\u0026rsquo;s what we are going to see today.\nThe command btrfs inspect-internal logical-resolve, as stated in a previous post, is useful when the btrfs filesystem reports a problem related to data consistency, for example:\n1 2  [2349645.383479] BTRFS error (device sda): bdev /dev/sda errs: wr 0, rd 0, flush 0, corrupt 19, gen 0 [2349645.383483] BTRFS error (device sda): unable to fixup (regular) error at logical 519704576 on dev /dev/sda   Btrfs uses blocks groups and chunks to map logical and physical addresses, respectively. The logical address is needed since btrfs has built-in support for multi device and raid.\nTo find what is corruped, we need to find what is the file corresponding to the reported logical address, and this is what logical-resolve was designed to do. This tool is currently failing on some cases, as shown below:\n1 2  $ btrfs inspect-internal logical-resolve 519704576 / ERROR: cannot access \u0026#39;//@/home\u0026#39;: No such file or directory   As we can see, the command returned -ENOENT and reported an odd path: \u0026rsquo;//@/home\u0026rsquo;. If you had a similar issue, this is most likely because you are using openSUSE/SLE as your Linux distribution, since these systems use @ as it\u0026rsquo;s top subvolume. For more details about the subvolume layout used in openSUSE check this post from Richard Brown.\nBy looking at the problematic path returned we can assume that logical-resolve is using the full subvolume path when searching for the file. This won\u0026rsquo;t work because the subvolume @ is not mounted, only it\u0026rsquo;s child subvolume home:\n1 2  $ mount -l | grep home /dev/sda2 on /home type btrfs (rw,relatime,ssd,space_cache,subvolid=263,subvol=/@/home)   In this case the tool should start looking at /home, or in other words, it should be looking at where the subvolume is mounted, not at the subvolume path.\nResolving the resolver We can describe the functionality of logical-resolve in the following steps:\n Execute ioctl BTRFS_IOC_LOGICAL_INO to get all inodes related to the logical address (519704576 in our example), in the root filesystem (/ in our case) For each returned inode  Call btrfs_list_path_for_root to get the subvolume path Concatenate the filesystem path (/ in our case) plus the returned subvolume path (/@/home in the example) Call btrfs_open_dir using the path create above (//@/home), returning an fd Call __ino_to_path_fd using the directory fd from btrfs_open_dir and the inode number If __ino_to_path_fd found a valid filename, print the full path (//@/home) plus the filename found.    From the steps shown above we can see that step 2.3 will fail. The path /@ is not accessible, only /home. We can fix the problem by changing the behavior and getting the subvolue mount point instead of the subvolume path.\nAn astute reader would think that we can get wrong mount points too, like a bind mount that points to a directory within our desired mount point. This was fixed by the commit mentioned in a previous post.\nWith the bind mount problem resolved, the fixing is a matter of changing step 2.2, like what was done in this patch:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  char *mounted = NULL; char subvol[PATH_MAX]; char subvolid[PATH_MAX]; /* * btrfs_list_path_for_root returns the full * path to the subvolume pointed by root, but the * subvolume can be mounted in a directory name * different from the subvolume name. In this * case we need to find the correct mount point * using same subvolume path and subvol id found * before. */ snprintf(subvol, PATH_MAX, \u0026#34;/%s\u0026#34;, name); snprintf(subvolid, PATH_MAX, \u0026#34;%llu\u0026#34;, root); ret = find_mount_fsroot(subvol, subvolid, \u0026amp;mounted); if (ret) { error(\u0026#34;failed to parse mountinfo\u0026#34;); goto out; } if (!mounted) { printf( \u0026#34;inode %llu subvol %s could not be accessed: not mounted\\n\u0026#34;, inum, name); continue; }   The new behavior searches for all currently mounted filesystems in order to find the correct mount point related to the subvolume name and subvolume id returned from the BTRFS_IOC_LOGICAL_INO ioctl. This is done by function find_mount_fsroot.\nWith the most recent version of btrfs-progs, logical-resolve works as expected:\n1 2  $ btrfs inspect-internal logical-resolve 5085913088 / //./home/marcos/.local/share/flatpak/repo/objects/00/7e3655177d55a02ca39d4cd3d095627f824b8004ad70f416eccb8bdd281fd5.file   The package btrfs-progs v5.10 already contains the fixes pointed in this post, so make sure to upgrade your package in order to have a working logical-resolve.\nThanks for reading!\n","permalink":"https://mpdesouza.com/blog/btrfs-resolving-the-logical-resolve/","summary":"Tools like fsck and smartctl are usually used when something bad happens on your disk. But, what if such tools have a problem and also need to be fixed? Well, that\u0026rsquo;s what we are going to see today.\nThe command btrfs inspect-internal logical-resolve, as stated in a previous post, is useful when the btrfs filesystem reports a problem related to data consistency, for example:\n1 2  [2349645.383479] BTRFS error (device sda): bdev /dev/sda errs: wr 0, rd 0, flush 0, corrupt 19, gen 0 [2349645.","title":"Btrfs: Resolving the logical-resolve"},{"content":"The btrfs inspect-internal logical-resolve command is used to find a file related to a logical-address. This can be useful when btrfs reports a corruption at an specific logical address, making it easy for the user to find the corrupted file. But, for all current users of openSUSE/SUSE Enterprise Linux, this command was failing as shown below:\n1 2  btrfs inspect-internal logical-resolve 5085913088 / ERROR: cannot access \u0026#39;//@/home\u0026#39;: No such file or directory   An openSUSE/SLE installation would create a set of subvolumes, starting from /@. These subvolumes are mounted on /, but @ is never mounted. For example, subvolume /@/home is mounted at /home. We can confirm this behavior by looking at the subvolume list:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  $ btrfs subvolume list / ID 256 gen 32 top level 5 path @ ID 257 gen 416148 top level 256 path @/var ID 258 gen 416148 top level 256 path @/usr/local ID 259 gen 416148 top level 256 path @/tmp ID 260 gen 405918 top level 256 path @/srv ID 261 gen 362296 top level 256 path @/root ID 262 gen 371476 top level 256 path @/opt ID 263 gen 416148 top level 256 path @/home ID 264 gen 131967 top level 256 path @/boot/grub2/x86_64-efi ID 265 gen 28 top level 256 path @/boot/grub2/i386-pc ID 266 gen 354001 top level 256 path @/.snapshots ID 267 gen 416148 top level 266 path @/.snapshots/1/snapshot ID 274 gen 53 top level 266 path @/.snapshots/2/snapshot ID 280 gen 2186 top level 266 path @/.snapshots/7/snapshot ...   By checking the fstab file we can verify that all subvolumes are mounted at /, but starting from the subvolume \u0026lsquo;@\u0026rsquo;:\n1 2 3 4 5  $ cat /etc/fstab ... UUID=35b19e1f-efb2-49a5-ab93-03c04e6d0399 /opt btrfs subvol=/@/opt 0 0 UUID=35b19e1f-efb2-49a5-ab93-03c04e6d0399 /home btrfs subvol=/@/home 0 0 ...   The code related to logical-address look at the full subvolume path (/@/home) and tries to follow it, but subvolume /@ isn\u0026rsquo;t mounted, returning an error. To address it, we need to find the exact mountpoint of the subvolume where the file is mounted, and show the path starting from it.\nThese two patches (patch 1, path 2) fix the issue: finding the correct mountpoint of a subvolume and using it to show the path to the file related to the logical-address.\nIn this post I\u0026rsquo;ll discuss about the first patch: how to reliably find the correct mountpoint related to a subvolume and a subvolume id.\nSearching for mounted subvolumes As btrfs mount options always show subvolume and subvolume id, it would be simple as:\n1 2  $ cat /proc/mounts | grep btrfs | grep \u0026#34;subvolid=5,subvol=/\u0026#34; /storage/btrfs/1.disk on /mnt type btrfs (rw,relatime,ssd,space_cache,subvolid=5,subvol=/)   The command above searches in the /proc/mounts file which contain all mountpoints, source, target, filesystem type and filesystem options used to mount.\nIn this case, it works as expect, but what if we have a bind mount mounting from a directory within the current mountpoint? Look at the example below:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # create a new disk, format it, create a subvolume and a directory on it $ fallocate -l5G test.disk $ mkfs.btrfs -f test.disk $ mount test.disk /mnt $ btrfs subvolume create /mnt/vol1 Create subvolume \u0026#39;/mnt/vol1\u0026#39; $ mount -o subvol=vol1 /mnt $ mkdir /mnt/dir1 $ cat /proc/mounts | grep btrfs | grep \u0026#34;subvolid=256,subvol=/vol1\u0026#34; /storage/btrfs/test.disk on /mnt type btrfs (rw,relatime,ssd,space_cache,subvolid=256,subvol=/vol1) $ umount /mnt # bind mount it $ mkdir another_mnt $ mount -o subvol=vol1 /mnt $ mount --bind /mnt/dir1 another_mnt   Now, if we run the same command as before, we have a problem:\n1 2 3  $ cat /proc/mounts | grep btrfs | grep \u0026#34;subvolid=256,subvol=/vol1\u0026#34; /storage/btrfs/test.disk on /mnt type btrfs (rw,relatime,ssd,space_cache,subvolid=256,subvol=/vol1) /storage/btrfs/test.disk on /storage/btrfs/another_mnt type btrfs (rw,relatime,ssd,space_cache,subvolid=256,subvol=/vol1)   As shown, the subvolid and subvol fields are the same, but the content isn\u0026rsquo;t:\n1 2 3 4  $ ls /mnt dir1 $ ls /storage/btrfs/another_mnt $   Prior to kernel 5.9-rc1, btrfs would show a diferent subvol= option when a bind mount was used. The issue was fixed by this patch. Before this change the /proc/mounts file would differentiate bind mounts:\n1 2  /dev/sda /mnt/test btrfs rw,relatime,subvolid=256,subvol=/foo 0 0 /dev/sda /mnt/test/baz btrfs rw,relatime,subvolid=256,subvol=/foo/bar 0 0   This was wrong, since the subvolume shown should be the same for a bind mount. The patch above fixed the behavior, and now a bind mount will show the same subvol and subvolid fields on a mountpoint:\n1 2  /dev/sda /mnt/test btrfs rw,relatime,subvolid=256,subvol=/foo 0 0 /dev/sda /mnt/test/baz btrfs rw,relatime,subvolid=256,subvol=/foo 0 0   As /proc/mounts can\u0026rsquo;t be used to differentiate bind mounts, how can we proceed?\nUsing /proc/\u0026lt;pid\u0026gt;/mountinfo There is a different proc file that shows all mountpoints, accessible by /proc/\u0026lt;pid\u0026gt;/mountinfo. The \u0026lt;pid\u0026gt; comes form the fact that the process can be in a different mount namespace. By using the pid the kernel knows which mountpoints are visible to the process. You can also use self if you want the mountpoints of the current process namespace.\nThe description of all mountinfo fields, along with the /proc/mounts one, can be see in the procfs manpage.\nWhat does mountinfo shows in this setup?\n1 2 3  cat /proc/self/mountinfo | grep btrfs | grep \u0026#34;subvolid=256,subvol=/vol1\u0026#34; 37 28 0:31 /vol1 /mnt rw,relatime - btrfs /dev/loop0 rw,ssd,space_cache,subvolid=256,subvol=/vol1 36 29 0:31 /vol1/dir1 /storage/btrfs/another_mnt rw,relatime - btrfs /dev/loop0 rw,ssd,space_cache,subvolid=256,subvol=/vol1   By looking at the forth field, we can see an interesting info. The manpage describes this field as:\n root: the pathname of the directory in the filesystem which forms the root of this mount.\n The mountinfo proc file can show the path within the filesystem used at the mount time. In this case, we just need to check if the forth field contains the same subvolume path specified in the filesystem options.\nWhat if we create a bind mount using the same directory of the original mount?\n1 2 3 4 5  $ umount another_mnt $ mount --bind /mnt/ another_mnt $ cat /proc/self/mountinfo | grep btrfs | grep \u0026#34;subvolid=256,subvol=/vol1\u0026#34; 37 28 0:31 /vol1 /mnt rw,relatime - btrfs /dev/loop0 rw,ssd,space_cache,subvolid=256,subvol=/vol1 36 29 0:31 /vol1 /storage/btrfs/another_mnt rw,relatime - btrfs /dev/loop0 rw,ssd,space_cache,subvolid=256,subvol=/vol1   As we can see, both mount roots are the same since both mountpoints have the same contents. The bind mount is just another way of accessing the same content of /mnt.\nI used this approach in this patch in order to solve one of the logical-resolve issues when running the comannd on a openSUSE/SLE distribution. Now the command runs correctly and reports the file related to a logical-address in the filesystem:\n1 2  btrfs inspect-internal logical-resolve 5085913088 / //./home/marcos/.local/share/flatpak/repo/objects/00/7e3655177d55a02ca39d4cd3d095627f824b8004ad70f416eccb8bdd281fd5.file   The patch was merged and is already part of btrfs-progs v5.10.1 along with other important fixes.\nThanks for reading!\n","permalink":"https://mpdesouza.com/blog/btrfs-differentiating-bind-mounts-on-subvolumes/","summary":"The btrfs inspect-internal logical-resolve command is used to find a file related to a logical-address. This can be useful when btrfs reports a corruption at an specific logical address, making it easy for the user to find the corrupted file. But, for all current users of openSUSE/SUSE Enterprise Linux, this command was failing as shown below:\n1 2  btrfs inspect-internal logical-resolve 5085913088 / ERROR: cannot access \u0026#39;//@/home\u0026#39;: No such file or directory   An openSUSE/SLE installation would create a set of subvolumes, starting from /@.","title":"btrfs: Differentiating bind mounts on subvolumes"},{"content":"The send/receive is a feature from btrfs where you can generate a stream of changes between two snapshots and then apply to any btrfs system, being a different disk on the host or over the network.\nThe receive feature receives a stream of data, applying the it in the filesystem. As the stream can be a file, it\u0026rsquo;s easy even to transfer the output of send over the network and receive in the other side. Here is an example of how this works:\n1  $ btrfs send /mnt/my_snapshot | ssh user@host \u0026#34;btrfs receive /mnt/my_backup\u0026#34;   In this example, we are doing what we call a full send, which sends all data to the remote side. We can see what is being processed by the receiving side by using --dump argument:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  # creating a \u0026#34;disk\u0026#34; and the btrfs filesystem $ truncate -s 10G btrfs.disk $ mkfs.btrfs -f btrfs.disk # creating a subvolume and a snapshot with one file $ mount btrfs.disk /mnt $ btrfs subvolume create /mnt/vol1 Create subvolume \u0026#39;/mnt/vol1\u0026#39; $ touch /mnt/vol1/file.txt $ btrfs subvolume snapshot -r /mnt/vol1/ /mnt/snap1 Create a readonly snapshot of \u0026#39;/mnt/vol1/\u0026#39; in \u0026#39;/mnt/snap1\u0026#39; # create a full send stream from snap1 $ btrfs send /mnt/snap1 -f send.dump # dumping the contents of the stream $ btrfs receive -f send.dump --dump subvol ./snap1 uuid=50ce3050-4ff1-f441-8202-7e49f3ac9657 transid=7 chown ./snap1/ gid=0 uid=0 chmod ./snap1/ mode=755 utimes ./snap1/ atime=2020-05-08T16:32:50-0300 mtime=2020-05-08T16:33:07-0300 ctime=2020-05-08T16:33:07-0300 mkfile ./snap1/o257-7-0 rename ./snap1/o257-7-0 dest=./snap1/file.txt utimes ./snap1/ atime=2020-05-08T16:32:50-0300 mtime=2020-05-08T16:33:07-0300 ctime=2020-05-08T16:33:07-0300 chown ./snap1/file.txt gid=0 uid=0 chmod ./snap1/file.txt mode=644 utimes ./snap1/file.txt atime=2020-05-08T16:33:07-0300 mtime=2020-05-08T16:33:07-0300 ctime=2020-05-08T16:33:07-0300 # creating a subvolume to store the backups (this coudld be done in a different disk) $ btrfs subvolume create /mnt/bkp Create subvolume \u0026#39;/mnt/bkp\u0026#39; # applying the receiving the stream $ btrfs receive -f send.dump /mnt/bkp $ ls /mnt/bkp/snap1/file.txt /mnt/bkp/snap1/file.txt   As we could see by the outputs above, the full send really specifies all actions, from the first snapshot creation, creation of files, adding a owner/group/mode and access time.\nAfter we have a backup, we can send just incremental changes. We call this an incremental send. We use a parent snapshot (-p argument) and compare it with a new snapshot. Look at the example below, using the same snapshots created in the steps above:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # changing user/group of file.txt $ ls -l /mnt/vol1/file.txt -rw-r--r-- 1 root root 0 May 8 16:33 /mnt/vol1/file.txt $ chgrp 100 /mnt/vol1/file.txt $ chown users /mnt/vol1/file.txt $ ls -l /mnt/vol1/file.txt -rw-r--r-- 1 marcos users 0 May 8 16:33 /mnt/vol1/file.txt # create a new snapshot based in the current version of vol1 $ btrfs subvolume snapshot -r /mnt/vol1/ /mnt/snap2 Create a readonly snapshot of \u0026#39;/mnt/vol1/\u0026#39; in \u0026#39;/mnt/snap2\u0026#39; # create a new stream by comparing snap1 with snap2, and dumping the changes $ btrfs send -p /mnt/snap1/ /mnt/snap2 -f send.dump $ btrfs receive -f send.dump --dump snapshot ./snap2 uuid=16343add-4e38-e343-9af2-f64ff7d4b61d transid=15 parent_uuid=50ce3050-4ff1-f441-8202-7e49f3ac9657 parent_transid=7 utimes ./snap2/ atime=2020-05-08T16:41:26-0300 mtime=2020-05-08T16:33:07-0300 ctime=2020-05-08T16:33:07-0300 chown ./snap2/file.txt gid=100 uid=1001 utimes ./snap2/file.txt atime=2020-05-08T16:33:07-0300 mtime=2020-05-08T16:33:07-0300 ctime=2020-05-08T16:42:06-0300 # applying changes  $ btrfs receive -f send.dump /mnt/bkp/ $ ls -l /mnt/bkp/snap2/file.txt -rw-r--r-- 1 marcos users 0 May 8 16:33 /mnt/bkp/snap2/file.txt   This is what we call an incremental send. In this case, if we have a file that exists in both snapshots, but in the most recent one it only changed the owner/group, the send stream will contain only the chown command, instead of copying the content of the file over the network again. The receive side will apply the chown, and then the filesystem on the remote/local host will have the content of the most recent version.\nThis feature works nicely for all users, but there is a corner case when it comes to file capabilities.\nWhat is the problem with capabilities? Capabilities can be set per file, and they are meant to give part of the root powers to a common binary to be executed like it\u0026rsquo;s root, but without the over permissive setuid bit.\nWith the setuid, the application runs as root, but using capabilities the application still runs as your current user, but with a subset of the root powers, like CAP_KILL (the permission to kill other programs) or CAP_SYS_NICE (the permission to change the priority of other processes).\nIf you change the user or group of a file with capabilities, the kernel drops the capability.\nThe problem is: if you have a parent snapshot that contains a file with capabilities and the file changed the owner and later restored the capability, the current kernel code emits only the chown, making the receive side to drop the capability, even if the parent snapshot still has the same capability set.\nThis problem exists in all stable releases since v4.4.\nIt\u0026rsquo;s easy to reproduce the problem:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # create a new sparse file with 5G of size, and create a btrfs fs on it $ fallocate -l5G disk.btrfs $ mkfs.btrfs disk.btrfs # mount the fs and create subvolumes fs1 and fs2  $ mount disk.btrfs /mnt $ btrfs subvolume create /mnt/fs1 $ btrfs subvolume create /mnt/fs2 # create a foo.bar file on fs1,and set a capabilities on it $ touch /mnt/fs1/foo.bar $ setcap cap_sys_nice+ep /mnt/fs1/foo.bar # create a readonly snapshot and send to fs2 (full send)  $ btrfs subvol snap -r /mnt/fs1 /mnt/fs1/snap_init $ btrfs send /mnt/fs1/snap_init | btrfs receive /mnt/fs2 # change the capability on foo.bar, and restore the capability $ chgrp adm /mnt/fs1/foo.bar $ setcap cap_sys_nice+ep /mnt/fs1/foo.bar # create a new readonly snapshot containing foo.bar with different group $ btrfs subvol snap -r /mnt/fs1 /mnt/fs1/snap_inc # executing an incremental send comparing the two snapshots $ btrfs send -p /mnt/fs1/snap_init /mnt/fs1/snap_inc | btrfs receive fs2   At this point, the foo.bar sent to fs2 lost it\u0026rsquo;s capability:\n1 2  $ getcap /mnt/fs2/snap_init/foo.bar $   How to fix the issue? Simple: just emit the capabilities after the chown was emitted. The basic idea is:\n Emit chown Check if there are capabilities for this file If yes, emit them  Here is a portion of the fix:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  if (need_chown) { ret = send_chown(sctx, sctx-\u0026gt;cur_ino, sctx-\u0026gt;cur_inode_gen, left_uid, left_gid); if (ret \u0026lt; 0) goto out; } if (need_chmod) { ret = send_chmod(sctx, sctx-\u0026gt;cur_ino, sctx-\u0026gt;cur_inode_gen, left_mode); if (ret \u0026lt; 0) goto out; } ret = send_capabilities(sctx); if (ret \u0026lt; 0) goto out;   The patch itself is somewhat bigger, and exposes how btrfs managed inodes and its attributes, and I plan to write about it in the future.\nFor the most curious readers, here is the full path. Along with the patch solving the problem, a test was created in xfstests to ensure this problem won\u0026rsquo;t happen again in the future.\nThe kernel patch was merged in v5.8 and backported to affected all stale kernels.\nThanks for reading! See you in another post!\n","permalink":"https://mpdesouza.com/blog/btrfs-making-send-more-capable/","summary":"The send/receive is a feature from btrfs where you can generate a stream of changes between two snapshots and then apply to any btrfs system, being a different disk on the host or over the network.\nThe receive feature receives a stream of data, applying the it in the filesystem. As the stream can be a file, it\u0026rsquo;s easy even to transfer the output of send over the network and receive in the other side.","title":"btrfs: making \"send\" more \"capable\""},{"content":"I\u0026rsquo;m Marcos, a Kernel Livepatch developer at SUSE.\nI have contributed to some interesting projects, like Linux Kernel, libvirt, LibreOffice, among others.\nFeel free to reach me out on Twitter, LinkedIn or email.\n","permalink":"https://mpdesouza.com/about-me/","summary":"I\u0026rsquo;m Marcos, a Kernel Livepatch developer at SUSE.\nI have contributed to some interesting projects, like Linux Kernel, libvirt, LibreOffice, among others.\nFeel free to reach me out on Twitter, LinkedIn or email.","title":"About me"},{"content":"Btrfs is a very versatile filesystem, and it has a lot of features that don\u0026rsquo;t exist in any other mainline Linux filesystem. One of the key features of btrfs is the concept of subvolumes. A subvolume can be compared to a disk partition since each subvolume can contain it\u0026rsquo;s own filesystem tree and size limits. When created, subvolumes are shown as directories in the directory they were created.\nCreating a subvolume is as easy as creating a directory:\n1  $ btrfs subvolume create \u0026lt;mount point\u0026gt;/volume_name   The same can be said of deleting a subvolume:\n1  $ btrfs subvolume delete \u0026lt;mount point\u0026gt;/volume_name   As each subvolume can contain a different filesystem, you can even mount a subvolume as it was a partition:\n1  $ mount /dev/sdX -o subvol=volume_name \u0026lt;mount_point\u0026gt;/   But, if it has sibling subvolumes, let\u0026rsquo;s say subvol1 and subvol2 created under \u0026lt;mount_point\u0026gt;, when mounting subvol2 especially the user can\u0026rsquo;t reach subvol1 in the same \u0026lt;mount_point\u0026gt;. Let\u0026rsquo;s see an example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  # allocate a 1G file $ fallocate -l 1G btrfs_fs # create a btrfs filesystem on it $ mkfs.btrfs btrfs_fs # mount it on /mnt $ mount btrfs_fs /mnt # create two subvolumes $ btrfs subvolume create /mnt/subvol1 $ btrfs subvolume create /mnt/subvol1 # list the subvolumes $ btrfs subvolume list /mnt ID 256 gen 6 top level 5 path subvol1 ID 257 gen 7 top level 5 path subvol2 $ ls /mnt subvol1 subvol2 # create a file unders each subvol directory $ touch /mnt/subvol1/file1 $ touch /mnt/subvol2/file2 $ ls -R /mnt /mnt: subvol1 subvol2 /mnt/subvol1: file1 /mnt/subvol2: file2   As you can see, two files were created. But, if the user mounts a specific subvolume under /mnt it won\u0026rsquo;t be able to reach the other subvolume by the same mount point.\n1 2 3 4 5 6 7 8 9  $ umount /mntmount btrfs_fs -o subvol=subvol2 /mnt $ ls -R /mnt /mnt: file2 $ btrfs subvolume list /mnt ID 256 gen 6 top level 5 path subvol1 ID 257 gen 7 top level 5 path subvol2   By the code above, subvol1 can\u0026rsquo;t be reached anymore, but it\u0026rsquo;s listed by subvolume list. Up until now, to remove a subvolume, the user should be able to reach it from the mount point. With the given example, the only way to delete the subvolume is to mount the filesystem in another mount point and delete subvol1:\n1 2 3 4 5 6 7  $ mount btrfs_fs /tmp/test $ ls /tmp/test subvol1 subvol2 $ btrfs subvolume delete /tmp/test/subvol1 Delete subvolume (no-commit): \u0026#39;/tmp/test/subvol1\u0026#39;   Recent commits in Linux kernel and btrfs-progs package changed this situation. By using the --subvolid argument a user can specify subvolume to be deleted:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  $ btrfs subvolume list /mnt ID 256 gen 6 top level 5 path subvol1 ID 258 gen 7 top level 5 path subvol2 $ ls -R /mnt /mnt: file2 $ btrfs subvolume delete --subvolid 256 /mnt Delete subvolume (no-commit): \u0026#39;/mnt/subvol1\u0026#39; $ btrfs subvolume list /mnt ID 256 gen 6 top level 5 path subvol1 ID 258 gen 7 top level 5 path subvol2   A new ioctl, BTRFS_IOC_SNAP_DESTROY_V2, was added in Linux kernel, and support for this ioctl was added in btrfs-progs and libbtrfsutil to make it possible. One possible user of this new feature is snapper, which has to deal with subvolume creation and deletion from time to time.\nIf you want to dig deeper into the details of this feature, take a look at the feature request and in the commits in Linux Kernel, btrfs-progs and a test at xfstests.\nThanks for reading!\n","permalink":"https://mpdesouza.com/blog/new-btrfs-feature-delete-subvolumes-using-subvolume-ids/","summary":"Btrfs is a very versatile filesystem, and it has a lot of features that don\u0026rsquo;t exist in any other mainline Linux filesystem. One of the key features of btrfs is the concept of subvolumes. A subvolume can be compared to a disk partition since each subvolume can contain it\u0026rsquo;s own filesystem tree and size limits. When created, subvolumes are shown as directories in the directory they were created.\nCreating a subvolume is as easy as creating a directory:","title":"New btrfs feature: Delete subvolumes using subvolume ids"},{"content":"After chasing the problem of rotational sysfs property of USB flash drives, I started to check another sysfs attributes of USB storage devices, and I noted two missing attributes: vpd_pg80 and vpd_pg83.\nAs explained here, VPD pages contain data related to the device. In special, page 80 is Unit Serial Number (sn) and page 83 is Device Information (di), which are present in any SCSI device that complies with SPC-2 or later.\nCheck an example of my sn and di of my SSD using sg_vpd from sg3_utils package:\n1 2 3 4 5 6 7 8 9 10 11  $ sg_vpd --page 0x80 /dev/sda Unit serial number VPD page: Unit serial number: FS71N654610101U37 $ sg_vpd --page 0x83 /dev/sda Device Identification VPD page: Addressed logical unit: designator type: vendor specific [0x0], code set: ASCII vendor specific: FS71N654610101U37 designator type: T10 vendor identification, code set: ASCII vendor id: ATA vendor specific: SK hynix SC300 SATA 512GB FS71N654610101U37   This information is exported as attributes of storage devices in sysfs, like my HDD and SSD devices below:\n1 2 3 4 5  $ ls /sys/block/sd[ab]/device/vpd* /sys/block/sda/device/vpd_pg80 /sys/block/sda/device/vpd_pg83 /sys/block/sdb/device/vpd_pg80 /sys/block/sdb/device/vpd_pg83   This is true for the majority of storage devices, but not for USB flash drives. Most USB storage devices dont have these attributes in sysfs, even when sg_vpd clearly shows them, like below:\n1 2 3 4 5 6 7 8 9 10 11  $ sg_vpd --page 0x80 /dev/sdc Unit serial number VPD page: Unit serial number: 4C530001300722111594 $ sg_vpd --page 0x83 /dev/sdc Device Identification VPD page: Addressed logical unit: designator type: T10 vendor identification, code set: ASCII vendor id: SanDisk vendor specific: Cruzer Blade $ ls /sys/block/sdc/device/vpd* zsh: no matches found: /sys/block/sdc/device/vpd*   Ive tested a bunch of different USB flash devices and USB to SATA adapters in my previous post, and neither of them had vpd_pg80 and vpd_pg83 in sysfs, although all SanDisk Cruzer Blade devices tested expose these VPD pages (thanks to my friend Alexandre Vicenzi who also had a Cruzer Blades to test).\nIn order to understand the problem, I decided to look at the kernel code. By using grep, I found a couple of interesting files:\n1 2 3 4  $ git grep -l pg80 drivers/scsi/scsi.c drivers/scsi/scsi_sysfs.c include/scsi/scsi_device.h   At first glance, scsi_sysfs.c seems the best place to start. This file describes the sysfs attributes of SCSI devices, like vpd_pg80 and how the values of this properly is presented. So far, no information from where it is assigned.\nFile scsi.c had some answers. Looking at function scsi_attach_vpd, we can clearly see where the SCSI layer checks for Device Information and Serial Number.\nBut, lets look at the first function that scsi_attach_vpd calls:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  /** * scsi_device_supports_vpd - test if a device supports VPD pages * @sdev: the \u0026amp;amp;struct scsi_device to test * * If the \u0026#39;try_vpd_pages\u0026#39; flag is set it takes precedence. * Otherwise we will assume VPD pages are supported if the * SCSI level is at least SPC-3 and \u0026#39;skip_vpd_pages\u0026#39; is not set. */ static inline int scsi_device_supports_vpd(struct scsi_device *sdev) { /* Attempt VPD inquiry if the device blacklist explicitly calls * for it. */ if (sdev-\u0026gt;try_vpd_pages) return 1; /* * Although VPD inquiries can go to SCSI-2 type devices, * some USB ones crash on receiving them, and the pages * we currently ask for are mandatory for SPC-2 and beyond */ if (sdev-\u0026gt;scsi_level \u0026gt;= SCSI_SPC_2 \u0026amp;\u0026amp; !sdev-\u0026gt;skip_vpd_pages) return 1; return 0; }   By looking at this function we can presume that try_vpd_pages flag is not set and skip_vpd_pages is. We can discard checking scsi_level because Cruzer Blade is SPC-4 compliant:\n1 2 3  $ sg_inq /dev/sdc | head -2 standard INQUIRY: PQual=0 Device_type=0 RMB=1 LU_CONG=0 version=0x06 [SPC-4]   By looking at the comment of scsi_device_supports_vpd, some USB devices crash after checking their VPD pages, in this case, it makes sense to not enable VPD for all devices. Although, our SanDisk Cruzer Blade device clearly supports VPD and does not crash.\nscsi_device_supports_vpd is called in two places: scsi_add_lun and scsi_rescan_device. These callers are common path of device setup, so fixing skip_vpd_pages should be enough.\nLets grep again in the kernel source code to check where skip_vpd_pages is being set:\n1 2 3 4 5  $ git grep -l skip_vpd_pages drivers/scsi/scsi.c drivers/scsi/scsi_scan.c drivers/usb/storage/scsiglue.c include/scsi/scsi_device.h   Interesting to see that USB layer setting this flag. Lets check drivers/usb/stoarge/scsiglue.c file:\n1 2  /* Some devices don\u0026#39;t handle VPD pages correctly */ sdev-\u0026gt;skip_vpd_pages = 1;   By the code above, which belongs to slave_configure function, USB layer disables VPD for all USB storage devices. Makes sense, since some devices are reported to crash when checking for VPD, as stated before.\nBut, shouldnt we add support for SanDisk Cruzer Blade at least? There is a per device mapping with specific flags in SCSI layer that should help to fix this situation, specially regarding try_vpd_pages. To add support for SanDisk Cruzer Blade* devices, I submited this patch to the kernel mailing list and its now merged:\n1 2 3 4 5  {\u0026#34;LENOVO\u0026#34;, \u0026#34;Universal Xport\u0026#34;, \u0026#34;*\u0026#34;, BLIST_NO_ULD_ATTACH}, + {\u0026#34;SanDisk\u0026#34;, \u0026#34;Cruzer Blade\u0026#34;, NULL, BLIST_TRY_VPD_PAGES | + BLIST_INQUIRY_36},  {\u0026#34;SMSC\u0026#34;, \u0026#34;USB 2 HS-CF\u0026#34;, NULL, BLIST_SPARSELUN | BLIST_INQUIRY_36}, ...   The patch adds specific flags that will be checked in SCSI layer and will be applied once the SanDisk Cruzer Blade* device is found. This change alone does not fix the problem as the flag skip_vpd_pages is still enabled. So I submited a second patch, to only set skip_vpd_pages when try_vpd_pages is not set allowing the SCSI layer to process all VPD pages when try_vpd_pages is set.\n1 2 3 4 5 6 7  - /* Some devices don\u0026#39;t handle VPD pages correctly */ - sdev-\u0026gt;skip_vpd_pages = 1; + /* + * Some devices don\u0026#39;t handle VPD pages correctly, so skip vpd + * pages if not forced by SCSI layer. + */ + sdev-\u0026gt;skip_vpd_pages = !sdev-\u0026gt;try_vpd_pages;   With these two patches applied SanDisk Cruzer Blade USB flash device is able to properly show the VPD pages in sysfs:\n1 2 3 4 5 6 7 8 9 10 11  $ cat /sys/block/sda/device/vendor SanDisk $ cat /sys/block/sda/device/model Cruzer Blade $ cat /sys/block/sda/device/vpd_pg80 4C530001300722111594 $ cat /sys/block/sda/device/vpd_pg83 0,SanDiskCruzer Blade4C530001300722111594   Thats all for today. Stay tuned for more posts about Kernel and whatnot, see ya!\n","permalink":"https://mpdesouza.com/blog/kernel-adventures-enabling-vpd-pages-for-usb-storage-devices-in-sysfs/","summary":"After chasing the problem of rotational sysfs property of USB flash drives, I started to check another sysfs attributes of USB storage devices, and I noted two missing attributes: vpd_pg80 and vpd_pg83.\nAs explained here, VPD pages contain data related to the device. In special, page 80 is Unit Serial Number (sn) and page 83 is Device Information (di), which are present in any SCSI device that complies with SPC-2 or later.","title":"Kernel Adventures: Enabling VPD Pages for USB Storage Devices in sysfs"},{"content":"A while ago Ive found this kernel bug entry about USB mass storage being shown as a rotational device. This is wrong because a USB stick is a flash device, and does not rotate.\nAbout rotational devices Lets take a minute to discuss about the evolution from disk to flash storage.\nOlder storage devices, HDD in this example, were called Disk Storage because these devices recorded data into one or more rotating disks. In such devices, the rotation speed was a feature that informed how fast the device was. A device with 5400 RPM (Rotations Per Minute) was slower than a device with 7200 RPM, for example.\n An example of a working HDD, a rotational disk. Reference: https://www.behance.net/gallery/25354853/HDD-Animation\n These devices were known to spend a large amount of time only to position the arm/head of the disk in the right sector/track to read the desired data. If a disk spins faster, so you can get your data faster.\nFlash Storage USB sticks and SSD storage devices are Non-Volatile Memory, which is much faster when compared to the disk storage because they dont need a mechanical rotational procedure to find the stored data. Data is stored in an array of transistors, and the seek time to find the desired data is constant while seek time can vary in rotational devices due to the position of the head needed to be positioned in different places of storage disk.\n Inside of a SSD device. Reference: https://www.backblaze.com/blog/hdd-versus-ssd-whats-the-diff/\n Back to the bug My idea was to check the kernel code in order to understand how it works. First of all, USB mass storage uses SCSI commands to transfer data between host and USB device. With this in mind, there are two layers in kernel to check: SCSI and USB.\nBy looking at Linux kernel code, specifically function sd_revalidate_disk in drivers/scsi/sd.c:\n1 2 3 4 5 6 7  /* * set the default to rotational. All non-rotational devices * support the block characteristics VPD page, which will * cause this to be updated correctly and any device which * doesnt support it should be treated as rotational. */ blk_queue_flag_clear(QUEUE_FLAG_NONROT, q);   This function is called when a disk is detected. It first sets the disk as rotational, by clearing the NONROT flag (yes, its confusing at first glance). A few lines bellow this point, we can see the following code:\n1 2 3 4 5 6  if (scsi_device_supports_vpd(sdp)) { sd_read_block_provisioning(sdkp); sd_read_block_limits(sdkp); sd_read_block_characteristics(sdkp); sd_zbc_read_zones(sdkp, buffer); }   We need some background about VPD. VPD stands for Vital Product Data, and presents information and configuration about a device, a SCSI device in this case. VPD was introduced in SCSI Primary Commands (SPC) 2 specification, and can be queried from any SCSI storage device by using sg_utils3 package:\n1 2 3 4 5 6 7 8 9  $ sg_vpd /dev/sda Supported VPD pages VPD page: Supported VPD pages [sv] Unit serial number [sn] Device identification [di] ATA information (SAT) [ai] Block limits (SBC) [bl] Block device characteristics (SBC) [bdc] Logical block provisioning (SBC) [lbpv]   This is the output of my SSD device. Going back to our original problem, rotating USB storage, the function sd_read_block_characteristics does something interesting:\n1 2 3 4 5 6 7 8 9 10 11  if (!buffer || /* Block Device Characteristics VPD */ scsi_get_vpd_page(sdkp-\u0026gt;device, 0xb1, buffer, vpd_len)) goto out; rot = get_unaligned_be16(buffer[4]); if (rot == 1) { blk_queue_flag_set(QUEUE_FLAG_NONROT, q); blk_queue_flag_clear(QUEUE_FLAG_ADD_RANDOM, q); }   The code above reads the Block Device Characteristics VPD page, which is present only in SPC-3 or later. Again, sg_vpd can help us to check BDC:\n1 2 3 4 5 6 7 8 9 10 11 12 13  $ sg_vpd  page bdc /dev/sda Block device characteristics VPD page (SBC): Non-rotating medium (e.g. solid state) Product type: Not specified WABEREQ=0 WACEREQ=0 Nominal form factor not reported ZONED=0 RBWZ=0 BOCS=0 FUAB=0 VBULS=0 DEPOPULATION_TIME=0 (seconds)   As you can see, the Block Device Characteristics of my SSD device says clearly: Non-rotation Medium. Per the function above, the NONROT flag will be set, so sysfs will show when reading the rotational attribute of this device:\n1 2  $ cat /sys/block/sda/queue/rotational 0   Moving further, I have another storage disk, now an HDD:\n1 2 3 4 5 6 7 8 9 10 11 12 13  $ sg_vpdpage bdc /dev/sdb Block device characteristics VPD page (SBC): Nominal rotation rate: 5400 rpm Product type: Not specified WABEREQ=0 WACEREQ=0 Nominal form factor not reported ZONED=0 RBWZ=0 BOCS=0 FUAB=0 VBULS=0 DEPOPULATION_TIME=0 (seconds)   Nominal rotation rate: 5400 rpm. Indeed, its a rotational device. But, what about USB sticks?\nIve tested more than 10 USB sticks and USB SATA adapters, and neither of them have BDC exposed. Lets use sg_inq to check if these which version of SCSI/SPC they implement, and which VPD they expose:\nAlcor Micro Corp. Flash Drive 058f:6387 (USB Stick) 1 2 3 4 5 6 7 8  $ sg_inq -s /dev/sdc standard INQUIRY: PQual=0 Device_type=0 RMB=1 LU_CONG=0 version=0x04 [SPC-2] $ sg_vpd --page 0x0 /dev/sdc Supported VPD pages VPD page: Supported VPD pages [sv] Unit serial number [sn] Device identification [di]   Chipsbank Microelectronics Co., Ltd 1e3d:2092 (USB Stick) 1 2 3 4 5 6 7 8 9  $ sg_inq /dev/sdc invalid VPD response; probably a STANDARD INQUIRY response standard INQUIRY: PQual=0 Device_type=0 RMB=1 LU_CONG=0 version=0x02 [SCSI-2] $ sg_vpd --page 0x0 /dev/sdc Supported VPD pages VPD page: invalid VPD response; probably a STANDARD INQUIRY response fetching VPD page failed: Malformed SCSI command sg_vpd failed: Malformed SCSI command   This device does not even implements VPD.\nHP, Inc 4 GB flash drive 03f0:3207 (USB stick) 1 2 3 4 5 6 7 8 9  $ sg_inq /dev/sdc invalid VPD response; probably a STANDARD INQUIRY response standard INQUIRY: PQual=0 Device_type=0 RMB=1 LU_CONG=0 version=0x00 [no conformance claimed] $ sg_vpd /dev/sdc Supported VPD pages VPD page: invalid VPD response; probably a STANDARD INQUIRY response fetching VPD page failed: Malformed SCSI command sg_vpd failed: Malformed SCSI command   This one is even worse, does not even comply with any specification.\nSanDisk Corp. Cruzer Blade 0781:5567 (USB Stick) 1 2 3 4 5 6 7 8  $ sg_inq /dev/sdc standard INQUIRY: PQual=0 Device_type=0 RMB=1 LU_CONG=0 version=0x06 [SPC-4] $ sg_vpd --page 0x0 /dev/sdc Supported VPD pages VPD page: Supported VPD pages [sv] Unit serial number [sn] Device identification [di]   This one from SanDisk complies with SPC-4, but no BDC supported either.\nSuper Top M6116 SATA Bridge 14cd:6116 (USB SATA adapter) 1 2 3 4 5  $ sg_inq /dev/sdc standard INQUIRY: PQual=0 Device_type=0 RMB=0 LU_CONG=0 version=0x00 [no conformance claimed] $ sg_vpd --page 0x0 /dev/sdc Supported VPD pages VPD page:   It doesnt show any VPD, but apprently understands the SCSI INQ command.\nInitio Corporation 13fd:3920 (USB SATA adapter) 1 2 3 4 5 6 7 8  $ sg_inq /dev/sdc standard INQUIRY: PQual=0 Device_type=0 RMB=0 LU_CONG=0 version=0x06 [SPC-4] $ sg_vpd --page 0x0 /dev/sdc Supported VPD pages VPD page: Supported VPD pages [sv] Unit serial number [sn] Device identification [di]   Another device which implements SPC-4 and does not expose BDC.\nConclusion Without Block Device Characteristics, the kernel cannot say for sure if the device is rotational or not, so the NONROT flag keeps cleared.\nThe rotational information can be used to change the IO scheduler related to the device, as openSUSE currently does:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  $ cat /usr/lib/udev/rules.d/60-io-scheduler.rules # Set optimal IO schedulers for HDD and SSD ACTION!=\u0026#34;add\u0026#34;, GOTO=\u0026#34;scheduler_end\u0026#34; SUBSYSTEM!=\u0026#34;block\u0026#34;, GOTO=\u0026#34;scheduler_end\u0026#34; # Do not change scheduler if `elevator` cmdline parameter is set IMPORT{cmdline}=\u0026#34;elevator\u0026#34; ENV{elevator}==\u0026#34;?*\u0026#34;, GOTO=\u0026#34;scheduler_end\u0026#34; # Determine if BLK-MQ is enabled TEST==\u0026#34;%S%p/mq\u0026#34;, ENV{.IS_MQ}=\u0026#34;1\u0026#34; # MQ: BFQ scheduler for HDD ENV{.IS_MQ}==\u0026#34;1\u0026#34;, ATTR{queue/rotational}!=\u0026#34;0\u0026#34;, ATTR{queue/scheduler}=\u0026#34;bfq\u0026#34; # MQ: deadline scheduler for SSD ENV{.IS_MQ}==\u0026#34;1\u0026#34;, ATTR{queue/rotational}==\u0026#34;0\u0026#34;, ATTR{queue/scheduler}=\u0026#34;mq-deadline\u0026#34; # Non-MQ: CFQ scheduler for HDD ENV{.IS_MQ}!=\u0026#34;1\u0026#34;, ATTR{queue/rotational}!=\u0026#34;0\u0026#34;, ATTR{queue/scheduler}=\u0026#34;cfq\u0026#34; # Non-MQ: deadline scheduler for SSD ENV{.IS_MQ}!=\u0026#34;1\u0026#34;, ATTR{queue/rotational}==\u0026#34;0\u0026#34;, ATTR{queue/scheduler}=\u0026#34;deadline\u0026#34; LABEL=\u0026#34;scheduler_end\u0026#34;   Picking the right IO scheduler helps to extract the best performancee of your storage device. For example BFQ IO scheduler would reorder read/write requests, trying to make them contiguous in order to extract the best of performance from an HDD disk. Remember, HDD devices have the head that needs to be positioned in the right place to get your data, and avoiding it to be moved randomly helps to improve performance.\nThe above is true for HDD devices but doesnt help much SSD devices which dont have the performance penalty of the seek time, so mq-deadline would be a better solution for this cases. This scheduler prefer reads over writes not reordering requests, and thats all, making it perform better in SSD devices.\nStay tuned for our next topic about IO schedulers and other things related to block layer. See you next time!\n","permalink":"https://mpdesouza.com/blog/kernel-adventures-are-usb-sticks-rotational-devices/","summary":"A while ago Ive found this kernel bug entry about USB mass storage being shown as a rotational device. This is wrong because a USB stick is a flash device, and does not rotate.\nAbout rotational devices Lets take a minute to discuss about the evolution from disk to flash storage.\nOlder storage devices, HDD in this example, were called Disk Storage because these devices recorded data into one or more rotating disks.","title":"Kernel Adventures: Are USB Sticks Rotational Devices?"},{"content":"Proposed in 2012, the NO_NEW_PRIVS flag made possible to any process to avoid privilege escalation when this behavior is not desired. After the flag is set, it persists across execve, clone and fork syscalls, and cannot be cleared. This can help you to avoid exploitation of vulnerable software, since the attacker will be running as an ordinary user.\nThe NO_NEW_PRIVS flag is already beeng used by some projects that try to make the running environment more secure, specially container engines and sandbox applications. Some examples are Docker, Bullewrap, and Firejail.\nThere are cases where privilege escalation is necessary, for example, to execute a small task that cant be done by an unprivileged user. This can be achieved by creating a new binary, that only do a very specific task, and have the setuid bit set (which change the current uid by the owner of the binary) or file capabilities(which can hold CAP_SYS_ADMIN for example, and so the current uid becomes practically root).\nAnother important note for NO_NEW_PRIVS is, after this flag is set, an unprivileged process can install seccomp_filters.\nAs described by the official kernel documentation about NO_NEW_PRIVS, this flag is set by using prctl, as exemplified below:\n1  prctl(PR_SET_NO_NEW_PRIVS, 1, 0, 0, 0);   Lets check how this works. First, we create a new binary called caller, which will be responsible for executing another binary, simply called getuid. The second binary will just print the current effective user. Lets take a look in both binaries, starting from caller:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #include \u0026lt;string.h\u0026gt;#include \u0026lt;sys/prctl.h\u0026gt;#include \u0026lt;unistd.h\u0026gt; int main(int argc, char **argv) { if (argc != 3) errx(0, \u0026#34;Usage: %s \u0026lt;0|1\u0026gt; \u0026lt;path to binary\u0026gt;\u0026#34;, argv[0]); if (!strncmp(argv[1], \u0026#34;1\u0026#34;, 1) \u0026amp;\u0026amp; prctl(PR_SET_NO_NEW_PRIVS, 1, 0, 0, 0) == -1) errx(1, \u0026#34;no_new_privs failed\u0026#34;); execlp(argv[2], argv[2], NULL); err(1, \u0026#34;execlp\u0026#34;); }   The first binary, caller, will receive two parameters, the first one specifies if the user wants to set the NO_NEW_PRIVS flag, and the second one receives a path to the binary we want to execute. After compiling getuid, we need to change the owner, and turn on the setuid bit of the resulting binary:\n1 2 3  $ gcc getuid.c -o getuid $ sudo chown root:root getuid $ sudo chmod +s getuid   Now, lets make use of both binaries. Lets assume you have them in the same directory. First, without setting NO_NEW_PRIVS:\n1 2  $ ./caller 0 ./getuid euid: 0   As expected, the printed effective user id is 0, meaning that we are root, thanks to the setuid bit being set and the owner of the binary being root. What happens when we turn on the NO_NEW_PRIVS flag in caller?\n1 2  $ ./caller 1 ./getuid euid: 1000   As expected, the effective user id is the one who executes caller, so, no privileges were escalated.\nWe can also exemplify this behavior using setpriv, which is part of util-linux, to test the NO_NEW_PRIVS flag. Take a look below:\n1 2 3 4  $ setpriv ./getuid euid: 0 $ setpriv --no-new-privs ./getuid euid: 1000   As you can see, the output is the same from the caller, as it uses the same feature to avoid privilege escalation.\nSo, the general suggestion is: always set NO_NEW_PRIVS whenever you dont need new privileges to be added to your process.\nSee you next time!\n","permalink":"https://mpdesouza.com/blog/no_new_privs-avoiding-privilege-escalation/","summary":"Proposed in 2012, the NO_NEW_PRIVS flag made possible to any process to avoid privilege escalation when this behavior is not desired. After the flag is set, it persists across execve, clone and fork syscalls, and cannot be cleared. This can help you to avoid exploitation of vulnerable software, since the attacker will be running as an ordinary user.\nThe NO_NEW_PRIVS flag is already beeng used by some projects that try to make the running environment more secure, specially container engines and sandbox applications.","title":"NO_NEW_PRIVS: avoiding privilege escalation"}]